{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_1M_DOMAINS = 'http://s3.amazonaws.com/alexa-static/top-1m.csv.zip'\n",
    "TOP_1M_DOMAINS_FILE = 'top-1m.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    top_doms = requests.get(TOP_1M_DOMAINS, stream=True)\n",
    "    zipfile = ZipFile(BytesIO(top_doms.content))\n",
    "    top_data = zipfile.read(TOP_1M_DOMAINS_FILE).decode('utf-8')\n",
    "\n",
    "    with open(TOP_1M_DOMAINS_FILE, 'w') as f:\n",
    "        f.write(top_data)\n",
    "\n",
    "def get_top_10_domain_zone():\n",
    "    top_data_df = pd.read_csv(TOP_1M_DOMAINS_FILE, names=['rank', 'domain'])\n",
    "    top_data_df['domain_zone'] = top_data_df['domain'].apply(lambda x: x.split('.')[-1])\n",
    "    top_10_domain_zone = top_data_df.groupby('domain_zone', as_index=False) \\\n",
    "                                    .agg({'domain': 'count'}) \\\n",
    "                                    .rename(columns={'domain': 'number'}) \\\n",
    "                                    .sort_values('number', ascending=False) \\\n",
    "                                    .head(10)\n",
    "    with open('top_10_domain_zone.csv', 'w') as f:\n",
    "        f.write(top_10_domain_zone.to_csv(index=False, header=False))\n",
    "\n",
    "def get_max_len_domain():\n",
    "    top_data_df = pd.read_csv(TOP_1M_DOMAINS_FILE, names=['rank', 'domain'])\n",
    "    top_data_df['len_name'] = top_data_df['domain'].apply(lambda x: len(x))\n",
    "    max_len_domain = top_data_df[['rank', 'domain', 'len_name']].sort_values('len_name') \\\n",
    "                                                                .tail(1)\n",
    "    with open('max_len_domain.csv', 'w') as f:\n",
    "        f.write(max_len_domain.to_csv(index=False, header=False))\n",
    "        \n",
    "def get_find_airflow():\n",
    "    top_data_df = pd.read_csv(TOP_1M_DOMAINS_FILE, names=['rank', 'domain'])\n",
    "    find = top_data_df.loc[top_data_df['domain'] == 'airflow.com']\n",
    "    if find['domain'].count() == 0:\n",
    "        rank_airflow = pd.DataFrame(np.array([['not_rank', 'airflow.com']]),\n",
    "                                    columns=['rank', 'domain'])\n",
    "    else:\n",
    "        rank_airflow = find\n",
    "        \n",
    "    with open('rank_airflow.csv', 'w') as f:\n",
    "        f.write(rank_airflow.to_csv(index=False, header=False))\n",
    "        \n",
    "def print_data(ds): # передаем глобальную переменную airflow\n",
    "    with open('top_10_domain_zone.csv', 'r') as f:\n",
    "        all_data_top_10_domain_zone = f.read()\n",
    "    with open('max_len_domain.csv', 'r') as f:\n",
    "        all_data_max_len_domain = f.read()\n",
    "    with open('rank_airflow.csv', 'r') as f:\n",
    "        all_data_find_airflow = f.read()\n",
    "    date = ds\n",
    "\n",
    "    print(f'Top 10 domains zone for date {date}')\n",
    "    print(all_data_top_10_domain_zone)\n",
    "\n",
    "    print(f'Max len of all domains for date {date}')\n",
    "    print(all_data_max_len_domain)\n",
    "    \n",
    "    print(f'Rank of domain \"airflow.com\" for date {date}')\n",
    "    print(all_data_find_airflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = {\n",
    "    'owner': 'a.gaybadulin',\n",
    "    'depends_on_past': False,\n",
    "    'retries': 2,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "    'start_date': datetime(2022, 11, 16),\n",
    "    'schedule_interval': '0 6 * * *'\n",
    "}\n",
    "dag = DAG('dag_a_gaybadulin', default_args=default_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = PythonOperator(task_id='get_data',\n",
    "                    python_callable=get_data,\n",
    "                    dag=dag)\n",
    "\n",
    "t2_1 = PythonOperator(task_id='get_top_10_domain_zone',\n",
    "                    python_callable=get_top_10_domain_zone,\n",
    "                    dag=dag)\n",
    "\n",
    "t2_2 = PythonOperator(task_id='get_max_len_domain',\n",
    "                        python_callable=get_max_len_domain,\n",
    "                        dag=dag)\n",
    "\n",
    "t2_3 = PythonOperator(task_id='get_find_airflow',\n",
    "                        python_callable=get_find_airflow,\n",
    "                        dag=dag)\n",
    "\n",
    "t3 = PythonOperator(task_id='print_data',\n",
    "                    python_callable=print_data,\n",
    "                    dag=dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task(PythonOperator): print_data>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 >> [t2_1, t2_2, t2_3] >> t3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
